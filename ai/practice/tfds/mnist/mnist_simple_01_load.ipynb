{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 21:29:32.571897: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-07 21:29:32.604707: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:absl:Load dataset info from /home/tmeng12/tensorflow_datasets/mnist/3.0.1\n",
      "INFO:absl:Fields info.[citation, splits, supervised_keys, module_name] from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset mnist (/home/tmeng12/tensorflow_datasets/mnist/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset mnist for split ['train', 'test'], from /home/tmeng12/tensorflow_datasets/mnist/3.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/datasets/keras_example\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging, os\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "BASE_PATH = \"../../../../../local_data/practice/tfds/\"\n",
    "DATA_PATH = \"../../../../../local_data/tfds/\"\n",
    "OUTPUT_PATH = BASE_PATH+\"mnist_simple_01/\"\n",
    "os.system(\"mkdir -p \" + OUTPUT_PATH)\n",
    "\n",
    "\n",
    "(train_ds, test_ds), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "print(f\"Number of training samples: {train_ds.cardinality()}\")\n",
    "print(f\"Number of test samples: {test_ds.cardinality()}\")\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(int(label))\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe65753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "1    1\n",
      "2    0\n",
      "3    7\n",
      "4    8\n",
      "5    1\n",
      "6    2\n",
      "7    7\n",
      "8    1\n",
      "9    6\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 21:29:34.899715: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "c1=tfds.as_dataframe(train_ds.take(10), ds_info)\n",
    "col1 = c1['label']\n",
    "# col1 = pd.DataFrame(train_ds, columns=[\"image\",\"train_ds\"])\n",
    "print(col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92facee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83dc02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.cache()\n",
    "# train_ds = train_ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e129a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "test_ds = test_ds.cache()\n",
    "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eeb7c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 6s 2ms/step - loss: 0.3957 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.2561 - val_sparse_categorical_accuracy: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7af91c0da4a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(batch_size, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=1,\n",
    "    validation_data=test_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab408f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3750,)\n",
      "3750/3750 [==============================] - 3s 670us/step\n",
      "                                                  label        p0         p1  \\\n",
      "0      [4, 1, 0, 7, 8, 1, 2, 7, 1, 6, 6, 4, 7, 7, 3, 3] -7.974104  -1.874438   \n",
      "1      [7, 9, 9, 1, 0, 6, 6, 9, 9, 4, 8, 9, 4, 7, 3, 3] -7.499573   4.179980   \n",
      "2      [0, 9, 4, 9, 0, 6, 8, 4, 7, 2, 6, 0, 3, 1, 1, 7]  6.075268 -10.879297   \n",
      "3      [2, 4, 4, 6, 5, 1, 9, 3, 2, 4, 3, 4, 4, 7, 5, 8] -3.154041 -13.878533   \n",
      "4      [1, 1, 4, 1, 5, 3, 5, 8, 4, 1, 1, 4, 5, 3, 2, 4] -2.916331  -8.122678   \n",
      "...                                                 ...       ...        ...   \n",
      "59995                                               NaN -7.877224 -12.248287   \n",
      "59996                                               NaN -9.165756   4.454875   \n",
      "59997                                               NaN  0.808035 -11.091747   \n",
      "59998                                               NaN -8.930107   5.770471   \n",
      "59999                                               NaN -1.994019  -9.150037   \n",
      "\n",
      "              p2        p3        p4        p5         p6        p7        p8  \\\n",
      "0      -5.273805 -4.320768  2.867625 -1.910296  -3.202208 -4.827733 -1.829898   \n",
      "1      -0.489544 -1.512232 -3.206689 -5.826322  -7.341101  0.522837 -1.525539   \n",
      "2      -2.485017 -4.591109 -6.118352 -0.547507  -0.456059 -9.184472 -3.823445   \n",
      "3      -3.756330 -5.254288 -3.901113 -6.598130 -13.759611  7.796967 -4.606932   \n",
      "4      -3.229439  0.186140 -7.288214 -1.350189  -7.740355 -7.406330  3.721932   \n",
      "...          ...       ...       ...       ...        ...       ...       ...   \n",
      "59995  -3.542810 -2.456888 -6.832332 -8.423465 -17.936378  9.128709 -3.723532   \n",
      "59996   0.713926 -1.059478 -2.504832 -7.305923  -9.681799  0.151455 -1.290978   \n",
      "59997  -0.823555 -4.643055 -3.505729  0.871068   5.821482 -8.144022 -4.670308   \n",
      "59998  -2.029844  0.075598 -1.987956 -1.968403  -3.813451 -3.635951 -0.635591   \n",
      "59999 -15.173927 -5.271510  3.092366  7.352747  -7.096550 -4.884930  2.183368   \n",
      "\n",
      "             p9  \n",
      "0     -1.067558  \n",
      "1     -2.542782  \n",
      "2     -4.921444  \n",
      "3     -0.971665  \n",
      "4     -5.105397  \n",
      "...         ...  \n",
      "59995 -0.262629  \n",
      "59996 -3.276188  \n",
      "59997 -7.392466  \n",
      "59998 -1.652932  \n",
      "59999 -2.828174  \n",
      "\n",
      "[60000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "c1=tfds.as_dataframe(train_ds.take(5000), ds_info)\n",
    "col1 = c1['label']\n",
    "print(col1.shape)\n",
    "\n",
    "pred = model.predict(train_ds)\n",
    "# print(\"pred\\n\",pred)\n",
    "# col2 = pd.DataFrame(pred[0:20], columns=[\"p0\",\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\",\"p7\",\"p8\",\"p9\"])\n",
    "col2 = pd.DataFrame(pred, columns=[\"p0\",\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\",\"p7\",\"p8\",\"p9\"])\n",
    "# print(col2)\n",
    "\n",
    "compare = pd.concat([col1, col2], axis=1)\n",
    "print(compare)\n",
    "compare.to_csv(OUTPUT_PATH + \"pred_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e687067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 867us/step\n",
      "                                                 label         p0         p1  \\\n",
      "0     [4, 1, 0, 7, 8, 1, 2, 7, 1, 6, 6, 4, 7, 7, 3, 3]  -3.265374  -4.515430   \n",
      "1     [7, 9, 9, 1, 0, 6, 6, 9, 9, 4, 8, 9, 4, 7, 3, 3]  10.253217 -17.563599   \n",
      "2     [0, 9, 4, 9, 0, 6, 8, 4, 7, 2, 6, 0, 3, 1, 1, 7]  -7.998972 -12.060715   \n",
      "3     [2, 4, 4, 6, 5, 1, 9, 3, 2, 4, 3, 4, 4, 7, 5, 8]  -4.729486   0.177743   \n",
      "4     [1, 1, 4, 1, 5, 3, 5, 8, 4, 1, 1, 4, 5, 3, 2, 4]  -4.226891 -12.413978   \n",
      "...                                                ...        ...        ...   \n",
      "9995                                               NaN  -1.599782  -7.026804   \n",
      "9996                                               NaN  -9.002808  -8.298120   \n",
      "9997                                               NaN  -4.201391  -8.996775   \n",
      "9998                                               NaN   9.253925 -12.211276   \n",
      "9999                                               NaN  -2.396875  -6.491379   \n",
      "\n",
      "            p2         p3        p4        p5         p6         p7        p8  \\\n",
      "0     4.591537  -1.174222 -4.993389 -3.067190  -6.298978  -8.205939 -4.971118   \n",
      "1    -1.198133 -10.301422 -8.405008  0.973717  -5.263607 -12.284986 -0.964807   \n",
      "2    -4.870873  -4.549546  4.958075 -8.436917  -6.745897   1.150829 -5.205309   \n",
      "3    -2.313173  -0.508000 -5.012874 -1.654255  -4.164176  -6.590121  3.600281   \n",
      "4    -3.061710  -3.171891 -3.951161 -6.993460 -14.772624   8.587796 -4.304127   \n",
      "...        ...        ...       ...       ...        ...        ...       ...   \n",
      "9995 -1.766222  -1.611026 -5.285413  4.414586  -0.011100 -10.379722  1.594089   \n",
      "9996 -8.046137   0.604056 -1.526220 -0.027025  -8.900262  -0.486503 -2.110397   \n",
      "9997 -3.099261  -4.357946 -4.356802 -1.190159  -0.373092 -15.163993  5.143875   \n",
      "9998 -3.235155  -3.673941 -6.485071 -0.711792  -7.125770  -6.516787 -3.303845   \n",
      "9999 -6.018752  -3.688976 -2.142224  7.147227  -3.094228  -9.343389  2.528220   \n",
      "\n",
      "            p9  \n",
      "0    -5.062407  \n",
      "1    -8.252603  \n",
      "2    -0.130314  \n",
      "3    -1.809015  \n",
      "4     0.110653  \n",
      "...        ...  \n",
      "9995 -4.586029  \n",
      "9996  3.949026  \n",
      "9997 -6.046017  \n",
      "9998 -5.720924  \n",
      "9999 -2.823527  \n",
      "\n",
      "[10000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_ds)\n",
    "# print(\"pred\\n\",pred)\n",
    "# col2 = pd.DataFrame(pred[0:20], columns=[\"p0\",\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\",\"p7\",\"p8\",\"p9\"])\n",
    "col2 = pd.DataFrame(pred, columns=[\"p0\",\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\",\"p7\",\"p8\",\"p9\"])\n",
    "# print(col2)\n",
    "\n",
    "compare = pd.concat([col1, col2], axis=1)\n",
    "print(compare)\n",
    "compare.to_csv(OUTPUT_PATH + \"pred_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

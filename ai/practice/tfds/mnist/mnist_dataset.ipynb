{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ae75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from ../../../../../local_data/tfds/mnist/3.0.1\n",
      "INFO:absl:Fields info.[citation, splits, supervised_keys, module_name] from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset mnist (../../../../../local_data/tfds/mnist/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset mnist for split ['train', 'test'], from ../../../../../local_data/tfds/mnist/3.0.1\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/datasets/keras_example\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging, os\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "BASE_PATH = \"../../../../../local_data/practice/tfds/\"\n",
    "DATA_PATH = \"../../../../../local_data/tfds/\"\n",
    "OUTPUT_PATH = BASE_PATH+\"mnist_simple_fit/\"\n",
    "os.system(\"mkdir -p \" + OUTPUT_PATH)\n",
    "\n",
    "\n",
    "(train_ds, test_ds), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    data_dir=DATA_PATH,\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8154922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {train_ds.cardinality()}\")\n",
    "print(f\"Number of test samples: {test_ds.cardinality()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f9fed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_path='../../../../../local_data/tfds/mnist/3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7367cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeaturesDict({\n",
      "    'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds_info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92157261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "print(ds_info.features[\"label\"].num_classes)\n",
    "print(ds_info.features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1a4784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': (28, 28, 1), 'label': ()}\n",
      "{'image': tf.uint8, 'label': tf.int64}\n",
      "(28, 28, 1)\n",
      "<dtype: 'uint8'>\n",
      "()\n",
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "print(ds_info.features.shape)\n",
    "print(ds_info.features.dtype)\n",
    "print(ds_info.features['image'].shape)\n",
    "print(ds_info.features['image'].dtype)\n",
    "print(ds_info.features['label'].shape)\n",
    "print(ds_info.features['label'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe65753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     4\n",
      "1     1\n",
      "2     0\n",
      "3     7\n",
      "4     8\n",
      "5     1\n",
      "6     2\n",
      "7     7\n",
      "8     1\n",
      "9     6\n",
      "10    6\n",
      "11    4\n",
      "12    7\n",
      "13    7\n",
      "14    3\n",
      "15    3\n",
      "16    7\n",
      "17    9\n",
      "18    9\n",
      "19    1\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 21:34:04.211639: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "c1=tfds.as_dataframe(train_ds.take(20), ds_info)\n",
    "col1 = c1['label']\n",
    "# col1 = pd.DataFrame(train_ds, columns=[\"image\",\"train_ds\"])\n",
    "print(col1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

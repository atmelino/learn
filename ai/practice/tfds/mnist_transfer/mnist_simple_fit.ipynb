{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36ae75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/tmeng12/tensorflow_datasets/mnist/3.0.1\n",
      "INFO:absl:Fields info.[citation, splits, supervised_keys, module_name] from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset mnist (/home/tmeng12/tensorflow_datasets/mnist/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset mnist for split ['train', 'test'], from /home/tmeng12/tensorflow_datasets/mnist/3.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds: <_PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/datasets/keras_example\n",
    "# without transfer learning\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging, os\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "BASE_PATH = \"../../../../../local_data/practice/tfds/\"\n",
    "DATA_PATH = \"../../../../../local_data/tfds/\"\n",
    "OUTPUT_PATH = BASE_PATH+\"mnist_simple_fit/\"\n",
    "os.system(\"mkdir -p \" + OUTPUT_PATH)\n",
    "\n",
    "\n",
    "(train_ds, test_ds), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "print(\"train_ds:\",train_ds)\n",
    "print(f\"Number of training samples: {train_ds.cardinality()}\")\n",
    "print(f\"Number of test samples: {test_ds.cardinality()}\")\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(int(label))\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe65753",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=tfds.as_dataframe(train_ds.take(20), ds_info)\n",
    "col1 = c1['label']\n",
    "# col1 = pd.DataFrame(train_ds, columns=[\"image\",\"train_ds\"])\n",
    "print(col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92facee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.cache()\n",
    "# train_ds = train_ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e129a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "test_ds = test_ds.cache()\n",
    "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(batch_size, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "model.summary()\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=1,\n",
    "    validation_data=test_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3d94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, test_ds), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "print(f\"Number of training samples: {train_ds.cardinality()}\")\n",
    "print(f\"Number of test samples: {test_ds.cardinality()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.cache()\n",
    "# train_ds = train_ds.shuffle(ds_info.splits['train'].num_examples)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab408f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=tfds.as_dataframe(train_ds.take(5000), ds_info)\n",
    "col1 = c1['label']\n",
    "print(col1.shape)\n",
    "\n",
    "pred = model.predict(train_ds)\n",
    "# print(\"pred\\n\",pred)\n",
    "col2 = pd.DataFrame(pred, columns=[\"p0\",\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\",\"p7\",\"p8\",\"p9\"])\n",
    "# print(col2)\n",
    "\n",
    "compare = pd.concat([col1, col2], axis=1)\n",
    "print(compare)\n",
    "compare.to_csv(OUTPUT_PATH + \"pred_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e687067",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_ds)\n",
    "# print(\"pred\\n\",pred)\n",
    "# col2 = pd.DataFrame(pred[0:20], columns=[\"p0\",\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\",\"p7\",\"p8\",\"p9\"])\n",
    "col2 = pd.DataFrame(pred, columns=[\"p0\",\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\",\"p7\",\"p8\",\"p9\"])\n",
    "# print(col2)\n",
    "\n",
    "compare = pd.concat([col1, col2], axis=1)\n",
    "print(compare)\n",
    "compare.to_csv(OUTPUT_PATH + \"pred_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

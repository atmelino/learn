{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d443e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import logging, os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE_PATH = \"../../../../../local_data/practice/tfds/\"\n",
    "DATA_PATH = \"../../../../../local_data/tfds/\"\n",
    "OUTPUT_PATH = BASE_PATH+\"mnist_transfer/\"\n",
    "os.system(\"mkdir -p \" + OUTPUT_PATH)\n",
    "\n",
    "train_dataset, validation_dataset = tfds.load(\n",
    "    \"mnist\",\n",
    "    data_dir=DATA_PATH,\n",
    "    split=[\"train[:40%]\", \"train[40%:50%]\"],\n",
    "    as_supervised=True,  # Include labels\n",
    ")\n",
    "\n",
    "num_train = tf.data.experimental.cardinality(train_dataset)\n",
    "num_test = tf.data.experimental.cardinality(validation_dataset)\n",
    "\n",
    "print(f\"Number of training samples: {num_train}\")\n",
    "print(f\"Number of validation samples: {num_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c6b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "for i, (image, label) in enumerate(train_dataset.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfefa12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_image(image, label):\n",
    "    image = tf.reshape(image, (28, 28, 1))\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(reshape_image)   \n",
    "def convert_to_rgb(image, label):\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(convert_to_rgb)   \n",
    "validation_dataset = validation_dataset.map(convert_to_rgb)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdacdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "for i, (image, label) in enumerate(train_dataset.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfee6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (150, 150)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "validation_dataset = validation_dataset.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = train_dataset.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "validation_dataset = validation_dataset.cache() \\\n",
    "    .batch(batch_size).prefetch(buffer_size=10)\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [layers.RandomFlip(\"horizontal\"), layers.RandomRotation(0.1),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e768c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34804529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(x)\n",
    "\n",
    "# The base model contains batchnorm layers. \n",
    "# We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, \n",
    "# so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(10)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21abbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ccbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "# model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)\n",
    "history =model.fit(train_dataset, epochs=epochs,validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc      = history.history[     'sparse_categorical_accuracy' ]\n",
    "val_acc  = history.history[ 'val_sparse_categorical_accuracy' ]\n",
    "loss     = history.history[    'loss' ]\n",
    "val_loss = history.history['val_loss' ]\n",
    "\n",
    "epochs_plot   = range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot  ( epochs_plot,     acc , label=\"training accuracy\")\n",
    "plt.plot  ( epochs_plot, val_acc, label=\"validation accuracy\" )\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot  ( epochs_plot,     loss , label=\"training loss\")\n",
    "plt.plot  ( epochs_plot, val_loss , label=\"validation loss\" )\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title ('Training and validation loss'   )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

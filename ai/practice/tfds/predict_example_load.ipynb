{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fcdfe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 14:37:35.791642: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-14 14:37:35.818231: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 233\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ../../../../local_data/practice/tfds/predict_example_01/acc_0.742_epochs_1.000_date_20250711-142521.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc_0.742_epochs_1.000_date_20250711-142521.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m fullpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 53\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jh_class/lib/python3.10/site-packages/keras/src/saving/saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    255\u001b[0m         filepath,\n\u001b[1;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jh_class/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/jh_class/lib/python3.10/site-packages/keras/src/saving/legacy/save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    241\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at ../../../../local_data/practice/tfds/predict_example_01/acc_0.742_epochs_1.000_date_20250711-142521.h5"
     ]
    }
   ],
   "source": [
    "# Explanation of prediction output when activation is sigmoid:\n",
    "# https://forum.freecodecamp.org/t/model-predict-output/470349\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import logging, os\n",
    "import pandas as pd\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE_PATH = \"../../../../local_data/practice/tfds/\"\n",
    "DATA_PATH = \"../../../../local_data/tfds/\"\n",
    "OUTPUT_PATH = BASE_PATH+\"predict_example_01/\"\n",
    "os.system(\"mkdir -p \" + OUTPUT_PATH)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "(train_dataset, test_dataset), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    data_dir=DATA_PATH,\n",
    "    # split=['train[:80%]', 'train[80%:]'],\n",
    "    split=['train[:80%]', 'train[99%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "print(f\"Number of test samples: {test_dataset.cardinality()}\")\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess)\n",
    "test_dataset = test_dataset.map(preprocess)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = train_dataset.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "test_dataset = test_dataset.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "\n",
    "# Load model\n",
    "filename = \"epochs_5.000_date_20250708-215035.h5\"\n",
    "filename = \"acc_0.966_epochs_8.000_date_20250710-211155.h5\"\n",
    "filename = \"acc_0.703_epochs_1.000_date_20250711-141215.h5\"\n",
    "filename = \"acc_0.742_epochs_1.000_date_20250711-142521.h5\"\n",
    "fullpath = f\"{OUTPUT_PATH}{filename}\"\n",
    "model = load_model(fullpath)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_dataset)\n",
    "allpreds=predictions.flatten()\n",
    "allpnorms = np.where(allpreds > 0.5, 1, 0)\n",
    "\n",
    "alllabels=np.empty(0)\n",
    "for images, labels in test_dataset:\n",
    "    alllabels = np.append(alllabels, labels.numpy().flatten())\n",
    "\n",
    "score = metrics.accuracy_score(alllabels, allpnorms)\n",
    "print(\"Validation accuracy score: {}\".format(score))\n",
    "\n",
    "collabels = pd.DataFrame(alllabels, columns=[\"l\"])\n",
    "colpreds = pd.DataFrame( allpreds, columns=[\"pred\"])\n",
    "pnorm = pd.DataFrame( allpnorms, columns=[\"pnorm\"])\n",
    "diff = collabels[\"l\"] - pnorm[\"pnorm\"]\n",
    "\n",
    "compare = pd.concat([collabels, colpreds,pnorm,diff], axis=1)\n",
    "compare.columns = [\"l\", \"pred\", \"pnorm\",\"diff\"]\n",
    "print(compare)\n",
    "\n",
    "compare.to_csv(OUTPUT_PATH + \"pred_test_load.csv\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=tfds.as_dataframe(test_dataset.take(4), metadata)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "(train_dataset, test_dataset), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    data_dir=DATA_PATH,\n",
    "    # split=['train[:80%]', 'train[80%:]'],\n",
    "    split=['train[:80%]', 'train[99%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(test_dataset.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

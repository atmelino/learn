{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with TensorFlow Datasets -part 3; An end to end example for building a Flower Classifier\n",
    "\n",
    "https://kvirajdatt.medium.com/starting-with-tensorflow-datasets-part-3-an-end-to-end-example-for-building-a-flowerclassifier-1b7c371447e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../../local_data/practice/tfds/kohir/\n",
      "../../../../../local_data/tfds/\n",
      "../../../../../local_data/practice/tfds/kohir/part3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import logging, os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "BASE_PATH = \"../../../../../local_data/practice/tfds/kohir/\"\n",
    "DATA_PATH = \"../../../../../local_data/tfds/\"\n",
    "OUTPUT_PATH = BASE_PATH+\"part3\"\n",
    "os.system(\"mkdir -p \" + OUTPUT_PATH)\n",
    "\n",
    "print(BASE_PATH)\n",
    "print(DATA_PATH)\n",
    "print(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from ../../../../../local_data/tfds/tf_flowers/3.0.1\n",
      "INFO:absl:Fields info.[splits, supervised_keys, module_name] from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset tf_flowers (../../../../../local_data/tfds/tf_flowers/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset tf_flowers for split ['train[:80%]', 'train[80%:90%]', 'train[90%:]'], from ../../../../../local_data/tfds/tf_flowers/3.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 2936\n",
      "Number of validation samples: 367\n",
      "Number of test samples: 367\n"
     ]
    }
   ],
   "source": [
    "# tfds.disable_progress_bar()\n",
    "\n",
    "#trainset, validationset, test-set, metadata\n",
    "(train_ds, val_ds, test_ds), metadata = tfds.load('tf_flowers',\n",
    "                data_dir=DATA_PATH,\n",
    "                split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "                with_info=True,\n",
    "                as_supervised=True,\n",
    "        )\n",
    "print(f\"Number of training samples: {train_ds.cardinality()}\")\n",
    "print(f\"Number of validation samples: {val_ds.cardinality()}\")\n",
    "print(f\"Number of test samples: {test_ds.cardinality()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape= (333, 500, 3)  label= 2\n",
      "(333, 500, 3) tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 21:27:09.071493: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-07-17 21:27:09.117897: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_ds.take(1):\n",
    "  print(\"image.shape=\",image.shape,\" label=\",int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds.show_examples(train_ds,metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.imshow(images[0])\n",
    "    # plt.title(metadata.features['label'].int2str(labels[0]))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.features\n",
    "# FeaturesDict({\n",
    "#     'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
    "#     'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),\n",
    "# })\n",
    "\n",
    "\n",
    "metadata.features['label']\n",
    "# ClassLabel(shape=(), dtype=tf.int64, num_classes=5)\n",
    "\n",
    "\n",
    "# Look at the labels\n",
    "metadata.features['label'].names\n",
    "# ['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses']\n",
    "\n",
    "\n",
    "# Look at how the classes are encoded\n",
    "for label in metadata.features['label'].names:\n",
    "  print(label,\",\" ,metadata.features['label'].str2int(label))\n",
    "\n",
    "  \n",
    "# Convert a encoded int label back to string\n",
    "print(2,\",\" ,metadata.features['label'].int2str(2))\n",
    "# 2 , tulips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of train examples', tf.data.experimental.cardinality(train_ds))\n",
    "print('Number of validation examples', tf.data.experimental.cardinality(val_ds))\n",
    "print('Number of test examples', tf.data.experimental.cardinality(test_ds))\n",
    "\n",
    "# Number of train examples tf.Tensor(92, shape=(), dtype=int64)\n",
    "# Number of validation examples tf.Tensor(12, shape=(), dtype=int64)\n",
    "# Number of test examples tf.Tensor(12, shape=(), dtype=int64)\n",
    "\n",
    "\n",
    "# Let's take a peak at a few images in the dataset\n",
    "for x,y in train_ds.take(4):\n",
    "  print(x.shape,y)\n",
    "  \n",
    "# (333, 500, 3) tf.Tensor(2, shape=(), dtype=int64)\n",
    "# (212, 320, 3) tf.Tensor(3, shape=(), dtype=int64)\n",
    "# (240, 320, 3) tf.Tensor(3, shape=(), dtype=int64)\n",
    "# (240, 320, 3) tf.Tensor(4, shape=(), dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a few hyperparameters\n",
    "IMG_SIZE = 150\n",
    "batch_size = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "# We can define the Resizing and Rescaling\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "# A function that resizes, rescales, batches and shuffles\n",
    "def prepare_images(ds, shuffle=False,):\n",
    "  \n",
    "  # Resize and rescale the dataset.\n",
    "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y),\n",
    "              num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Shuffles the dataset\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(1000)\n",
    "  \n",
    "  # Batch all datasets.\n",
    "  ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "## Let us resize and rescale the images in our dataset\n",
    "train_ds = prepare_images(train_ds)\n",
    "val_ds = prepare_images(val_ds)\n",
    "test_ds = prepare_images(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.imshow(images[0])\n",
    "    # plt.title(metadata.features['label'].int2str(labels[0]))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.imshow(images[0])\n",
    "    # plt.title(metadata.features['label'].int2str(labels[0]))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "for images, labels in train_ds.take(2):\n",
    "    plt.imshow(images[0])\n",
    "    plt.imshow(images[1])\n",
    "    \n",
    "    # plt.title(metadata.features['label'].int2str(labels[0]))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "t81_558_class_01_1_overview.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jh_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

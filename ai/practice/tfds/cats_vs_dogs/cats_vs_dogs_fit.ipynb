{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a1dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 18610\n",
      "Number of test samples: 4652\n"
     ]
    }
   ],
   "source": [
    "# Explanation of prediction output when activation is sigmoid:\n",
    "# https://forum.freecodecamp.org/t/model-predict-output/470349\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import logging, os\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "BASE_PATH = \"../../../../../local_data/practice/tfds/\"\n",
    "DATA_PATH = \"../../../../../local_data/tfds/\"\n",
    "OUTPUT_PATH = BASE_PATH+\"predict_example_01/\"\n",
    "os.system(\"mkdir -p \" + OUTPUT_PATH)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "(train_dataset, validation_dataset), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    data_dir=DATA_PATH,\n",
    "    # split=['train[:80%]', 'train[80%:]'],\n",
    "    # split=['train[:80%]', 'train[99%:]'],\n",
    "    split=['train[:5%]', 'train[5%:10%]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "print(f\"Number of train samples: {train_dataset.cardinality()}\")\n",
    "print(f\"Number of validation samples: {validation_dataset.cardinality()}\")\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess)\n",
    "validation_dataset = validation_dataset.map(preprocess)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "validation_dataset = validation_dataset.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "\n",
    "\n",
    "# Apply data augmentation\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, 0.1)\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(augment)\n",
    "\n",
    "\n",
    "# Model prediction\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dab3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs=2\n",
    "history =model.fit(train_dataset, epochs=epochs,validation_data=validation_dataset)\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc      = history.history[     'sparse_categorical_accuracy' ]\n",
    "val_acc  = history.history[ 'val_sparse_categorical_accuracy' ]\n",
    "loss     = history.history[    'loss' ]\n",
    "val_loss = history.history['val_loss' ]\n",
    "\n",
    "epochs   = range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot  ( epochs,     acc , label=\"training accuracy\")\n",
    "plt.plot  ( epochs, val_acc, label=\"validation accuracy\" )\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot  ( epochs,     loss , label=\"training loss\")\n",
    "plt.plot  ( epochs, val_loss , label=\"validation loss\" )\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title ('Training and validation loss'   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe2eb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 1s 8ms/step\n",
      "test dataset accuracy score: 0.6567067927773\n",
      "        l      pred  pnorm  diff\n",
      "0     1.0  0.583488      1   0.0\n",
      "1     0.0  0.459765      0   0.0\n",
      "2     1.0  0.792031      1   0.0\n",
      "3     1.0  0.697715      1   0.0\n",
      "4     1.0  0.579095      1   0.0\n",
      "...   ...       ...    ...   ...\n",
      "4647  0.0  0.232707      0   0.0\n",
      "4648  0.0  0.648843      1  -1.0\n",
      "4649  0.0  0.549263      1  -1.0\n",
      "4650  1.0  0.533914      1   0.0\n",
      "4651  0.0  0.451260      0   0.0\n",
      "\n",
      "[4652 rows x 4 columns]\n",
      "Saving model to  acc_0.657_epochs_1.000_date_20250718-211237.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/miniconda3/envs/jh_class/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(validation_dataset)\n",
    "allpreds=predictions.flatten()\n",
    "allpnorms = np.where(allpreds > 0.5, 1, 0)\n",
    "\n",
    "alllabels=np.empty(0)\n",
    "for images, labels in validation_dataset:\n",
    "    alllabels = np.append(alllabels, labels.numpy().flatten())\n",
    "\n",
    "score = metrics.accuracy_score(alllabels, allpnorms)\n",
    "print(\"test dataset accuracy score: {}\".format(score))\n",
    "\n",
    "collabels = pd.DataFrame(alllabels, columns=[\"l\"])\n",
    "colpreds = pd.DataFrame( allpreds, columns=[\"pred\"])\n",
    "pnorm = pd.DataFrame( allpnorms, columns=[\"pnorm\"])\n",
    "diff = collabels[\"l\"] - pnorm[\"pnorm\"]\n",
    "\n",
    "compare = pd.concat([collabels, colpreds,pnorm,diff], axis=1)\n",
    "compare.columns = [\"l\", \"pred\", \"pnorm\",\"diff\"]\n",
    "print(compare)\n",
    "\n",
    "compare.to_csv(OUTPUT_PATH + \"pred_test_fit.csv\", index=False)    \n",
    "\n",
    "# Save model\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "filename = f\"acc_{score:.3f}_epochs_{epochs:.3f}_date_{timestr}.h5\"\n",
    "fullpath = f\"{OUTPUT_PATH}{filename}\"\n",
    "print(\"Saving model to \", filename)\n",
    "model.save(fullpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

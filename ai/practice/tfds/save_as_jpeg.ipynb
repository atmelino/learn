{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c22efc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 20:54:22.449202: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-02 20:54:22.714300: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:absl:Load dataset info from ../../../../local_data/tfds/cats_vs_dogs/4.0.0\n",
      "INFO:absl:Reusing dataset cats_vs_dogs (../../../../local_data/tfds/cats_vs_dogs/4.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset cats_vs_dogs for split ['train[:40%]', 'train[40%:50%]'], from ../../../../local_data/tfds/cats_vs_dogs/4.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import logging, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "BASE_PATH = \"../../../../local_data/practice/\"\n",
    "DATA_PATH = \"../../../../local_data/tfds/\"\n",
    "OUTPUT_PATH = BASE_PATH+\"pr_class_09_2_keras_xfer_cv/\"\n",
    "os.system(\"mkdir -p \" + OUTPUT_PATH)\n",
    "\n",
    "(train_ds, validation_ds), metadata= tfds.load(\n",
    "    \"cats_vs_dogs\",\n",
    "    data_dir=DATA_PATH,\n",
    "    split=[\"train[:40%]\", \"train[40%:50%]\"],\n",
    "    with_info=True,\n",
    "    as_supervised=True, \n",
    ")# Include labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed0b1dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m         path_and_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, name\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m     20\u001b[0m         tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mwrite_file(path_and_name, serialized_im)\n\u001b[0;32m---> 23\u001b[0m \u001b[43msave_dataset_as_jpegs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpegs_train/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# save_dataset_as_jpegs(raw_validation, 'jpegs_validation/')\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# save_dataset_as_jpegs(raw_test, 'jpegs_test/')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36msave_dataset_as_jpegs\u001b[0;34m(dataset, path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03msaves every image to the 'path' using random name + target\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m:return: Nothing. Just saves the dataset as jpegs.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m---> 16\u001b[0m     im, name \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, obj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage/filename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     17\u001b[0m     serialized_im \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mencode_jpeg(im)\n\u001b[1;32m     19\u001b[0m     path_and_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, name\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mdecode())\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "def save_dataset_as_jpegs(\n",
    "    dataset,\n",
    "    path,\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    saves every image to the 'path' using random name + target\n",
    "\n",
    "    :param dataset: dataset you want to save\n",
    "    :param path: where you want to store it\n",
    "    :param metadata: metadata from dataset. required to get class names.\n",
    "    :return: Nothing. Just saves the dataset as jpegs.\n",
    "    \"\"\"\n",
    "\n",
    "    for obj in dataset:\n",
    "        im, name = obj[\"image\"], obj[\"image/filename\"]\n",
    "        serialized_im = tf.image.encode_jpeg(im)\n",
    "\n",
    "        path_and_name = os.path.join(path, name.numpy().decode())\n",
    "        tf.io.write_file(path_and_name, serialized_im)\n",
    "\n",
    "\n",
    "save_dataset_as_jpegs(train_ds, \"jpegs_train/\")\n",
    "# save_dataset_as_jpegs(raw_validation, 'jpegs_validation/')\n",
    "# save_dataset_as_jpegs(raw_test, 'jpegs_test/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

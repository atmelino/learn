{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08035dd4",
   "metadata": {},
   "source": [
    "Brave search: simple gradient tape model<br>\n",
    "https://www.linkedin.com/pulse/gradient-tape-deploy-descent-tensorflow-vu-hong-quan<br>\n",
    "https://github.com/quanvu0996/data_science/blob/main/tf/gradient_tape1_en.ipynb<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8e9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4502efcc",
   "metadata": {},
   "source": [
    "Generate dataset: 10 points near y=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a8d6e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[ 1.36800513  0.12304543  2.98533466  1.94784637  4.03841385  3.90775881\n",
      "  6.56710944  8.02524317  7.77652699 10.37077801]\n",
      "polyfit results:\n",
      "m= 1.051672749246733 b= -0.02152118556824941\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "print(x)\n",
    "\n",
    "# y=x+np.random.randint(10)\n",
    "# print(y)\n",
    "\n",
    "rng=np.random.default_rng(10)\n",
    "y=x+3*rng.random(10)-1.5\n",
    "print(y)\n",
    "\n",
    "m_fit,b_fit = np.polyfit(x, y, 1)\n",
    "\n",
    "# m,b=1,0\n",
    "print(\"polyfit results:\")\n",
    "print(\"m=\",m_fit,\"b=\",b_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "373616c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(number, X, Y, a, b):\n",
    "    plt.scatter(X, Y, color='purple')\n",
    "    plt.plot(X, a*X+b, color='steelblue', linestyle='--', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d78d164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_plot(0,x,y,m_fit,b_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f027a0b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a05cf009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def compute_loss(y_true, m,b):\n",
    "    y_pred=m*x+b\n",
    "    # print(y_pred)\n",
    "    loss = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b9c426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss= 0\n",
      "Loss= 0.6655171291941702\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss=\",compute_loss(x,1,0).numpy())    \n",
    "print(\"Loss=\",compute_loss(x,m_fit,b_fit).numpy())    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e25a8ec",
   "metadata": {},
   "source": [
    "optimization with only one variable (slope m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c209be2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: loss=321.73\n",
      "m= 0.06999953\n",
      "Iteration 2: loss=281.30\n",
      "m= 0.13983113\n",
      "Iteration 3: loss=243.75\n",
      "m= 0.20936519\n",
      "Iteration 4: loss=209.12\n",
      "m= 0.2784552\n",
      "Iteration 5: loss=177.45\n",
      "m= 0.34693956\n",
      "Iteration 6: loss=148.73\n",
      "m= 0.414639\n",
      "Iteration 7: loss=122.98\n",
      "m= 0.48135543\n",
      "Iteration 8: loss=100.15\n",
      "m= 0.5468731\n",
      "Iteration 9: loss=80.20\n",
      "m= 0.6109578\n",
      "Iteration 10: loss=63.06\n",
      "m= 0.6733585\n",
      "Iteration 11: loss=48.61\n",
      "m= 0.73380876\n",
      "Iteration 12: loss=36.73\n",
      "m= 0.7920303\n",
      "Iteration 13: loss=27.26\n",
      "m= 0.84773725\n",
      "Iteration 14: loss=20.01\n",
      "m= 0.9006419\n",
      "Iteration 15: loss=14.76\n",
      "m= 0.95046175\n",
      "Iteration 16: loss=11.28\n",
      "m= 0.9969274\n",
      "Iteration 17: loss=9.30\n",
      "m= 1.0397915\n",
      "Iteration 18: loss=8.57\n",
      "m= 1.0788374\n",
      "Iteration 19: loss=8.82\n",
      "m= 1.1138877\n",
      "Iteration 20: loss=9.78\n",
      "m= 1.144811\n",
      "Iteration 21: loss=11.21\n",
      "m= 1.1715281\n",
      "Iteration 22: loss=12.88\n",
      "m= 1.1940141\n",
      "Iteration 23: loss=14.60\n",
      "m= 1.2122998\n",
      "Iteration 24: loss=16.22\n",
      "m= 1.2264707\n",
      "Iteration 25: loss=17.60\n",
      "m= 1.2366631\n",
      "Iteration 26: loss=18.67\n",
      "m= 1.2430592\n",
      "Iteration 27: loss=19.36\n",
      "m= 1.2458816\n",
      "Iteration 28: loss=19.68\n",
      "m= 1.2453867\n",
      "Iteration 29: loss=19.62\n",
      "m= 1.2418582\n",
      "Iteration 30: loss=19.23\n",
      "m= 1.2356007\n",
      "Iteration 31: loss=18.55\n",
      "m= 1.2269336\n",
      "Iteration 32: loss=17.65\n",
      "m= 1.216186\n",
      "Iteration 33: loss=16.59\n",
      "m= 1.2036917\n",
      "Iteration 34: loss=15.43\n",
      "m= 1.1897842\n",
      "Iteration 35: loss=14.26\n",
      "m= 1.174793\n",
      "Iteration 36: loss=13.11\n",
      "m= 1.1590399\n",
      "Iteration 37: loss=12.05\n",
      "m= 1.142835\n",
      "Iteration 38: loss=11.10\n",
      "m= 1.1264744\n",
      "Iteration 39: loss=10.29\n",
      "m= 1.1102358\n",
      "Iteration 40: loss=9.64\n",
      "m= 1.0943769\n",
      "Iteration 41: loss=9.16\n",
      "m= 1.0791321\n",
      "Iteration 42: loss=8.82\n",
      "m= 1.0647101\n",
      "Iteration 43: loss=8.63\n",
      "m= 1.0512928\n",
      "Iteration 44: loss=8.55\n",
      "m= 1.0390327\n",
      "Iteration 45: loss=8.57\n",
      "m= 1.0280526\n",
      "Iteration 46: loss=8.67\n",
      "m= 1.0184449\n",
      "Iteration 47: loss=8.80\n",
      "m= 1.0102715\n",
      "Iteration 48: loss=8.96\n",
      "m= 1.0035647\n",
      "Iteration 49: loss=9.12\n",
      "m= 0.9983281\n",
      "Iteration 50: loss=9.26\n",
      "m= 0.9945383\n",
      "Iteration 51: loss=9.37\n",
      "m= 0.9921472\n",
      "Iteration 52: loss=9.45\n",
      "m= 0.9910841\n",
      "Iteration 53: loss=9.48\n",
      "m= 0.9912588\n",
      "Iteration 54: loss=9.48\n",
      "m= 0.9925645\n",
      "Iteration 55: loss=9.43\n",
      "m= 0.99488074\n",
      "Iteration 56: loss=9.36\n",
      "m= 0.99807686\n",
      "Iteration 57: loss=9.27\n",
      "m= 1.002015\n",
      "Iteration 58: loss=9.16\n",
      "m= 1.0065532\n",
      "Iteration 59: loss=9.05\n",
      "m= 1.0115485\n",
      "Iteration 60: loss=8.93\n",
      "m= 1.01686\n",
      "Iteration 61: loss=8.83\n",
      "m= 1.0223509\n",
      "Iteration 62: loss=8.74\n",
      "m= 1.0278914\n",
      "Iteration 63: loss=8.67\n",
      "m= 1.0333607\n",
      "Iteration 64: loss=8.61\n",
      "m= 1.0386488\n",
      "Iteration 65: loss=8.58\n",
      "m= 1.0436581\n",
      "Iteration 66: loss=8.56\n",
      "m= 1.0483043\n",
      "Iteration 67: loss=8.55\n",
      "m= 1.0525174\n",
      "Iteration 68: loss=8.56\n",
      "m= 1.0562423\n",
      "Iteration 69: loss=8.57\n",
      "m= 1.0594387\n",
      "Iteration 70: loss=8.59\n",
      "m= 1.062081\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = tf.Variable(initial_value=0.0, trainable=True)\n",
    "\n",
    "optimizer= tf.optimizers.Adam(learning_rate = .07)\n",
    "\n",
    "iterations = 70\n",
    "\n",
    "for i in range(1, iterations + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(y,m,0)\n",
    "    grads = tape.gradient(loss, m)\n",
    "    optimizer.apply_gradients([(grads, m)])\n",
    "    print(\"Iteration %d: loss=%.2f\" % (i, loss))\n",
    "    print(\"m=\",m.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e04261",
   "metadata": {},
   "source": [
    "optimization with both variables (slope m and offset b) in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db806c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def compute_loss_mb(y_true, mb):\n",
    "    # print(mb[0],mb[1])\n",
    "    y_pred=mb[0]*x+mb[1]\n",
    "    # print(y_pred)\n",
    "    loss = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca8b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: loss=248.19\n",
      "m= 0.36999822 b= 0.46999824\n",
      "Iteration 2: loss=113.24\n",
      "m= 0.63162947 b= 0.7304059\n",
      "Iteration 3: loss=36.06\n",
      "m= 0.8723358 b= 0.9660407\n",
      "Iteration 4: loss=11.53\n",
      "m= 1.0726942 b= 1.1531923\n",
      "Iteration 5: loss=24.70\n",
      "m= 1.2129884 b= 1.2697165\n",
      "Iteration 6: loss=51.39\n",
      "m= 1.2857649 b= 1.311194\n",
      "Iteration 7: loss=70.01\n",
      "m= 1.2982931 b= 1.2897896\n",
      "Iteration 8: loss=72.18\n",
      "m= 1.2642676 b= 1.2220044\n",
      "Iteration 9: loss=60.69\n",
      "m= 1.1974765 b= 1.122396\n",
      "Iteration 10: loss=42.70\n",
      "m= 1.1101651 b= 1.0029944\n",
      "Iteration 11: loss=25.41\n",
      "m= 1.0133868 b= 0.8742913\n",
      "Iteration 12: loss=13.90\n",
      "m= 0.91752404 b= 0.7460642\n",
      "Iteration 13: loss=10.30\n",
      "m= 0.83224577 b= 0.6275265\n",
      "Iteration 14: loss=13.67\n",
      "m= 0.7657355 b= 0.52670527\n",
      "Iteration 15: loss=20.75\n",
      "m= 0.7235678 b= 0.44936615\n",
      "Iteration 16: loss=27.54\n",
      "m= 0.70798564 b= 0.39817733\n",
      "Iteration 17: loss=30.99\n",
      "m= 0.7180314 b= 0.37263173\n",
      "Iteration 18: loss=29.99\n",
      "m= 0.7503029 b= 0.36964357\n",
      "Iteration 19: loss=25.35\n",
      "m= 0.79981494 b= 0.3843655\n",
      "Iteration 20: loss=19.07\n",
      "m= 0.86066335 b= 0.41089514\n",
      "Iteration 21: loss=13.38\n",
      "m= 0.9264943 b= 0.4428197\n",
      "Iteration 22: loss=9.94\n",
      "m= 0.99092466 b= 0.47370926\n",
      "Iteration 23: loss=9.35\n",
      "m= 1.0480405 b= 0.49766582\n",
      "Iteration 24: loss=11.08\n",
      "m= 1.0929813 b= 0.50992364\n",
      "Iteration 25: loss=13.84\n",
      "m= 1.1224811 b= 0.5073673\n",
      "Iteration 26: loss=16.15\n",
      "m= 1.1351868 b= 0.48880333\n",
      "Iteration 27: loss=16.98\n",
      "m= 1.131663 b= 0.454919\n",
      "Iteration 28: loss=16.07\n",
      "m= 1.114131 b= 0.40799993\n",
      "Iteration 29: loss=13.92\n",
      "m= 1.0860662 b= 0.35153204\n",
      "Iteration 30: loss=11.43\n",
      "m= 1.0517498 b= 0.28977528\n",
      "Iteration 31: loss=9.52\n",
      "m= 1.0158072 b= 0.22732832\n",
      "Iteration 32: loss=8.73\n",
      "m= 0.98273224 b= 0.16867287\n",
      "Iteration 33: loss=9.09\n",
      "m= 0.95641 b= 0.117704436\n",
      "Iteration 34: loss=10.14\n",
      "m= 0.9396914 b= 0.0773039\n",
      "Iteration 35: loss=11.22\n",
      "m= 0.9341011 b= 0.049033463\n",
      "Iteration 36: loss=11.79\n",
      "m= 0.93973607 b= 0.033022806\n",
      "Iteration 37: loss=11.60\n",
      "m= 0.9553597 b= 0.02805559\n",
      "Iteration 38: loss=10.79\n",
      "m= 0.9786485 b= 0.031815995\n",
      "Iteration 39: loss=9.75\n",
      "m= 1.0065358 b= 0.04123731\n",
      "Iteration 40: loss=8.91\n",
      "m= 1.0356084 b= 0.05290456\n",
      "Iteration 41: loss=8.57\n",
      "m= 1.0625232 b= 0.06347467\n",
      "Iteration 42: loss=8.74\n",
      "m= 1.0844077 b= 0.07007624\n",
      "Iteration 43: loss=9.21\n",
      "m= 1.0991946 b= 0.07064121\n",
      "Iteration 44: loss=9.67\n",
      "m= 1.1058418 b= 0.06411985\n",
      "Iteration 45: loss=9.88\n",
      "m= 1.1044015 b= 0.050548155\n",
      "Iteration 46: loss=9.74\n",
      "m= 1.0959396 b= 0.030966777\n",
      "Iteration 47: loss=9.34\n",
      "m= 1.0823288 b= 0.0072163194\n",
      "Iteration 48: loss=8.90\n",
      "m= 1.0659537 b= -0.018353727\n",
      "Iteration 49: loss=8.61\n",
      "m= 1.0493714 b= -0.043222748\n",
      "Iteration 50: loss=8.56\n",
      "m= 1.0349653 b= -0.06504332\n",
      "Iteration 51: loss=8.71\n",
      "m= 1.0246379 b= -0.081949055\n",
      "Iteration 52: loss=8.94\n",
      "m= 1.0195816 b= -0.092783675\n",
      "Iteration 53: loss=9.10\n",
      "m= 1.0201608 b= -0.09721891\n",
      "Iteration 54: loss=9.10\n",
      "m= 1.0259184 b= -0.09574806\n",
      "Iteration 55: loss=8.97\n",
      "m= 1.0356969 b= -0.08956434\n",
      "Iteration 56: loss=8.77\n",
      "m= 1.0478489 b= -0.08034984\n",
      "Iteration 57: loss=8.61\n",
      "m= 1.060503 b= -0.0700103\n",
      "Iteration 58: loss=8.56\n",
      "m= 1.0718448 b= -0.060394242\n",
      "Iteration 59: loss=8.61\n",
      "m= 1.0803753 b= -0.053035878\n",
      "Iteration 60: loss=8.71\n",
      "m= 1.0851086 b= -0.04895768\n",
      "Iteration 61: loss=8.79\n",
      "m= 1.0856831 b= -0.04855982\n",
      "Iteration 62: loss=8.80\n",
      "m= 1.0823715 b= -0.05160917\n",
      "Iteration 63: loss=8.74\n",
      "m= 1.0759964 b= -0.057323664\n",
      "Iteration 64: loss=8.65\n",
      "m= 1.0677685 b= -0.06453324\n",
      "Iteration 65: loss=8.58\n",
      "m= 1.0590769 b= -0.071888596\n",
      "Iteration 66: loss=8.56\n",
      "m= 1.0512663 b= -0.07808387\n",
      "Iteration 67: loss=8.58\n",
      "m= 1.0454342 b= -0.0820588\n",
      "Iteration 68: loss=8.63\n",
      "m= 1.0422789 b= -0.08315015\n",
      "Iteration 69: loss=8.66\n",
      "m= 1.0420197 b= -0.08117112\n",
      "Iteration 70: loss=8.66\n",
      "m= 1.0443983 b= -0.07641011\n",
      "Iteration 71: loss=8.63\n",
      "m= 1.048755 b= -0.0695541\n",
      "Iteration 72: loss=8.59\n",
      "m= 1.0541644 b= -0.061553627\n",
      "Iteration 73: loss=8.56\n",
      "m= 1.0596037 b= -0.05345453\n",
      "Iteration 74: loss=8.55\n",
      "m= 1.0641261 b= -0.046225283\n",
      "Iteration 75: loss=8.57\n",
      "m= 1.0670102 b= -0.04060815\n",
      "Iteration 76: loss=8.59\n",
      "m= 1.0678619 b= -0.03701711\n",
      "Iteration 77: loss=8.60\n",
      "m= 1.0666559 b= -0.035496812\n",
      "Iteration 78: loss=8.60\n",
      "m= 1.0637122 b= -0.03574558\n",
      "Iteration 79: loss=8.58\n",
      "m= 1.0596173 b= -0.03719455\n",
      "Iteration 80: loss=8.56\n",
      "m= 1.0551049 b= -0.03912604\n",
      "Iteration 81: loss=8.55\n",
      "m= 1.0509211 b= -0.040808592\n",
      "Iteration 82: loss=8.55\n",
      "m= 1.0476961 b= -0.04162473\n",
      "Iteration 83: loss=8.56\n",
      "m= 1.0458453 b= -0.041169968\n",
      "Iteration 84: loss=8.57\n",
      "m= 1.0455134 b= -0.039307836\n",
      "Iteration 85: loss=8.57\n",
      "m= 1.0465713 b= -0.0361741\n",
      "Iteration 86: loss=8.57\n",
      "m= 1.0486592 b= -0.032132875\n",
      "Iteration 87: loss=8.56\n",
      "m= 1.0512686 b= -0.027695514\n",
      "Iteration 88: loss=8.55\n",
      "m= 1.0538437 b= -0.02341913\n",
      "Iteration 89: loss=8.55\n",
      "m= 1.0558848 b= -0.0198041\n",
      "Iteration 90: loss=8.55\n",
      "m= 1.057033 b= -0.017209\n",
      "Iteration 91: loss=8.56\n",
      "m= 1.057124 b= -0.015797097\n",
      "Iteration 92: loss=8.56\n",
      "m= 1.0562032 b= -0.015522058\n",
      "Iteration 93: loss=8.56\n",
      "m= 1.0545003 b= -0.016152779\n",
      "Iteration 94: loss=8.55\n",
      "m= 1.0523725 b= -0.017330159\n",
      "Iteration 95: loss=8.55\n",
      "m= 1.0502281 b= -0.018643113\n",
      "Iteration 96: loss=8.55\n",
      "m= 1.0484475 b= -0.019708475\n",
      "Iteration 97: loss=8.55\n",
      "m= 1.0473131 b= -0.02023966\n",
      "Iteration 98: loss=8.55\n",
      "m= 1.046965 b= -0.020091994\n",
      "Iteration 99: loss=8.55\n",
      "m= 1.0473852 b= -0.01927785\n",
      "Iteration 100: loss=8.55\n",
      "m= 1.048414 b= -0.017950794\n",
      "Iteration 101: loss=8.55\n",
      "m= 1.0497915 b= -0.016363988\n",
      "Iteration 102: loss=8.55\n",
      "m= 1.0512154 b= -0.014812673\n",
      "Iteration 103: loss=8.55\n",
      "m= 1.0524027 b= -0.013572878\n",
      "Iteration 104: loss=8.55\n",
      "m= 1.0531427 b= -0.012848485\n",
      "Iteration 105: loss=8.55\n",
      "m= 1.0533316 b= -0.01273639\n",
      "Iteration 106: loss=8.55\n",
      "m= 1.0529846 b= -0.013215229\n",
      "Iteration 107: loss=8.55\n",
      "m= 1.0522225 b= -0.014158209\n",
      "Iteration 108: loss=8.55\n",
      "m= 1.0512393 b= -0.015365782\n",
      "Iteration 109: loss=8.55\n",
      "m= 1.0502571 b= -0.01661026\n",
      "Iteration 110: loss=8.55\n",
      "m= 1.0494798 b= -0.017682556\n",
      "Iteration 111: loss=8.55\n",
      "m= 1.0490534 b= -0.018431649\n",
      "Iteration 112: loss=8.55\n",
      "m= 1.0490409 b= -0.018789321\n",
      "Iteration 113: loss=8.55\n",
      "m= 1.0494167 b= -0.018776236\n",
      "Iteration 114: loss=8.55\n",
      "m= 1.0500784 b= -0.018489553\n",
      "Iteration 115: loss=8.55\n",
      "m= 1.0508747 b= -0.018075906\n",
      "Iteration 116: loss=8.55\n",
      "m= 1.05164 b= -0.01769645\n",
      "Iteration 117: loss=8.55\n",
      "m= 1.0522296 b= -0.017491726\n",
      "Iteration 118: loss=8.55\n",
      "m= 1.0525479 b= -0.017553614\n",
      "Iteration 119: loss=8.55\n",
      "m= 1.0525643 b= -0.017909655\n",
      "Iteration 120: loss=8.55\n",
      "m= 1.0523137 b= -0.018522175\n",
      "Iteration 121: loss=8.55\n",
      "m= 1.0518839 b= -0.019301174\n",
      "Iteration 122: loss=8.55\n",
      "m= 1.0513926 b= -0.020127287\n",
      "Iteration 123: loss=8.55\n",
      "m= 1.0509595 b= -0.020879159\n",
      "Iteration 124: loss=8.55\n",
      "m= 1.0506811 b= -0.021459142\n",
      "Iteration 125: loss=8.55\n",
      "m= 1.0506116 b= -0.02181191\n",
      "Iteration 126: loss=8.55\n",
      "m= 1.0507551 b= -0.021932535\n",
      "Iteration 127: loss=8.55\n",
      "m= 1.0510687 b= -0.021863142\n",
      "Iteration 128: loss=8.55\n",
      "m= 1.0514756 b= -0.021679673\n",
      "Iteration 129: loss=8.55\n",
      "m= 1.0518854 b= -0.02147244\n",
      "Iteration 130: loss=8.55\n",
      "m= 1.0522139 b= -0.02132517\n",
      "Iteration 131: loss=8.55\n",
      "m= 1.0524019 b= -0.021297198\n",
      "Iteration 132: loss=8.55\n",
      "m= 1.0524259 b= -0.021412514\n",
      "Iteration 133: loss=8.55\n",
      "m= 1.0522997 b= -0.021657575\n",
      "Iteration 134: loss=8.55\n",
      "m= 1.0520692 b= -0.02198758\n",
      "Iteration 135: loss=8.55\n",
      "m= 1.0517985 b= -0.022339253\n",
      "Iteration 136: loss=8.55\n",
      "m= 1.0515546 b= -0.022646729\n",
      "Iteration 137: loss=8.55\n",
      "m= 1.0513918 b= -0.022856725\n",
      "Iteration 138: loss=8.55\n",
      "m= 1.051341 b= -0.02293968\n",
      "Iteration 139: loss=8.55\n",
      "m= 1.0514042 b= -0.022894593\n",
      "Iteration 140: loss=8.55\n",
      "m= 1.051557 b= -0.022746995\n",
      "Iteration 141: loss=8.55\n",
      "m= 1.0517561 b= -0.022541057\n",
      "Iteration 142: loss=8.55\n",
      "m= 1.0519515 b= -0.022328125\n",
      "Iteration 143: loss=8.55\n",
      "m= 1.0520978 b= -0.022154504\n",
      "Iteration 144: loss=8.55\n",
      "m= 1.0521649 b= -0.022051422\n",
      "Iteration 145: loss=8.55\n",
      "m= 1.0521436 b= -0.022029351\n",
      "Iteration 146: loss=8.55\n",
      "m= 1.0520456 b= -0.0220776\n",
      "Iteration 147: loss=8.55\n",
      "m= 1.0518993 b= -0.022168832\n",
      "Iteration 148: loss=8.55\n",
      "m= 1.051742 b= -0.022267098\n",
      "Iteration 149: loss=8.55\n",
      "m= 1.0516098 b= -0.02233726\n",
      "Iteration 150: loss=8.55\n",
      "m= 1.0515295 b= -0.022353403\n",
      "Iteration 151: loss=8.55\n",
      "m= 1.0515134 b= -0.022304334\n",
      "Iteration 152: loss=8.55\n",
      "m= 1.0515572 b= -0.022195114\n",
      "Iteration 153: loss=8.55\n",
      "m= 1.0516427 b= -0.02204463\n",
      "Iteration 154: loss=8.55\n",
      "m= 1.0517431 b= -0.021880018\n",
      "Iteration 155: loss=8.55\n",
      "m= 1.0518311 b= -0.02172951\n",
      "Iteration 156: loss=8.55\n",
      "m= 1.0518843 b= -0.021615712\n",
      "Iteration 157: loss=8.55\n",
      "m= 1.0518911 b= -0.021550693\n",
      "Iteration 158: loss=8.55\n",
      "m= 1.0518523 b= -0.021534074\n",
      "Iteration 159: loss=8.55\n",
      "m= 1.0517799 b= -0.021554325\n",
      "Iteration 160: loss=8.55\n",
      "m= 1.0516928 b= -0.021592582\n",
      "Iteration 161: loss=8.55\n",
      "m= 1.0516124 b= -0.02162798\n",
      "Iteration 162: loss=8.55\n",
      "m= 1.0515561 b= -0.021642998\n",
      "Iteration 163: loss=8.55\n",
      "m= 1.0515344 b= -0.021627504\n",
      "Iteration 164: loss=8.55\n",
      "m= 1.0515481 b= -0.021580664\n",
      "Iteration 165: loss=8.55\n",
      "m= 1.0515894 b= -0.021510314\n",
      "Iteration 166: loss=8.55\n",
      "m= 1.0516442 b= -0.02143026\n",
      "Iteration 167: loss=8.55\n",
      "m= 1.0516968 b= -0.021356264\n",
      "Iteration 168: loss=8.55\n",
      "m= 1.0517334 b= -0.021301923\n",
      "Iteration 169: loss=8.55\n",
      "m= 1.0517457 b= -0.021275401\n",
      "Iteration 170: loss=8.55\n",
      "m= 1.0517323 b= -0.021277828\n",
      "Iteration 171: loss=8.55\n",
      "m= 1.0516987 b= -0.021303602\n",
      "Iteration 172: loss=8.55\n",
      "m= 1.051655 b= -0.021342337\n",
      "Iteration 173: loss=8.55\n",
      "m= 1.0516133 b= -0.021381915\n",
      "Iteration 174: loss=8.55\n",
      "m= 1.051584 b= -0.02141168\n",
      "Iteration 175: loss=8.55\n",
      "m= 1.0515734 b= -0.021425014\n",
      "Iteration 176: loss=8.55\n",
      "m= 1.0515826 b= -0.021420613\n",
      "Iteration 177: loss=8.55\n",
      "m= 1.0516075 b= -0.0214023\n",
      "Iteration 178: loss=8.55\n",
      "m= 1.0516404 b= -0.021377524\n",
      "Iteration 179: loss=8.55\n",
      "m= 1.0516723 b= -0.021355065\n",
      "Iteration 180: loss=8.55\n",
      "m= 1.0516953 b= -0.021342577\n",
      "Iteration 181: loss=8.55\n",
      "m= 1.0517046 b= -0.021344634\n",
      "Iteration 182: loss=8.55\n",
      "m= 1.0516994 b= -0.021361763\n",
      "Iteration 183: loss=8.55\n",
      "m= 1.0516828 b= -0.021390596\n",
      "Iteration 184: loss=8.55\n",
      "m= 1.0516609 b= -0.021425067\n",
      "Iteration 185: loss=8.55\n",
      "m= 1.0516404 b= -0.021458233\n",
      "Iteration 186: loss=8.55\n",
      "m= 1.051627 b= -0.021484178\n",
      "Iteration 187: loss=8.55\n",
      "m= 1.0516242 b= -0.021499421\n",
      "Iteration 188: loss=8.55\n",
      "m= 1.051632 b= -0.021503616\n",
      "Iteration 189: loss=8.55\n",
      "m= 1.0516479 b= -0.021499345\n",
      "Iteration 190: loss=8.55\n",
      "m= 1.0516672 b= -0.021491097\n",
      "Iteration 191: loss=8.55\n",
      "m= 1.0516849 b= -0.02148391\n",
      "Iteration 192: loss=8.55\n",
      "m= 1.0516965 b= -0.02148193\n",
      "Iteration 193: loss=8.55\n",
      "m= 1.0517 b= -0.021487355\n",
      "Iteration 194: loss=8.55\n",
      "m= 1.0516955 b= -0.021499982\n",
      "Iteration 195: loss=8.55\n",
      "m= 1.0516852 b= -0.0215175\n",
      "Iteration 196: loss=8.55\n",
      "m= 1.0516729 b= -0.021536281\n",
      "Iteration 197: loss=8.55\n",
      "m= 1.0516623 b= -0.021552524\n",
      "Iteration 198: loss=8.55\n",
      "m= 1.0516564 b= -0.021563275\n",
      "Iteration 199: loss=8.55\n",
      "m= 1.0516565 b= -0.02156718\n",
      "Iteration 200: loss=8.55\n",
      "m= 1.0516622 b= -0.021564715\n",
      "polyfit results:\n",
      "m= 1.051672749246733 b= -0.02152118556824941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mb = tf.Variable([0.1, 0.2])\n",
    "\n",
    "# optimizer= tf.optimizers.Adam(learning_rate = .07)\n",
    "optimizer= tf.optimizers.Adam(learning_rate = .27)\n",
    "\n",
    "iterations = 200\n",
    "\n",
    "for i in range(1, iterations + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # loss = compute_loss(y,m,b_fit)\n",
    "        loss = compute_loss_mb(y,mb)\n",
    "    grads = tape.gradient(loss, mb)\n",
    "    optimizer.apply_gradients([(grads, mb)])\n",
    "\n",
    "    print(\"Iteration %d: loss=%.2f\" % (i, loss))\n",
    "    print(\"m=\",mb[0].numpy(),\"b=\",mb[1].numpy())\n",
    "\n",
    "# printm= 1.051672749246733 b= -0.02152118556824941\n",
    "print(\"polyfit results:\")\n",
    "print(\"m=\",m_fit,\"b=\",b_fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jh_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
